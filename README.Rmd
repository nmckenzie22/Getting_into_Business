---
title: "README"
output: 
  github_document:
    pandoc_args: ["--wrap=none"]
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Download Dataset
```{r}
# Define the download URL
kaggle_url <- "https://www.kaggle.com/api/v1/datasets/download/fratzcan/usa-house-prices"

# Define the output file path
output_file <- file.path("./", "usa-house-prices.zip")

# Run the cURL command in R
system(paste("curl -L -o", shQuote(output_file), shQuote(kaggle_url)))

# Optional: Unzip the file
unzip(output_file, exdir = "./usa-house-prices")

# Confirm download
list.files("~/Downloads/usa-house-prices")
```

## Understanding the Data
When was the data acquired?
Where was the data acquired?

How was the data acquired?

What are the attributes of this dataset?
Below is R script code that loads the USA Housing Dataset and creates a data dictionary table based on the descriptions provided on Kaggle.
```{r}
#install.packages("readr")   # For reading CSV files
#install.packages("dplyr")   # For data manipulation
#install.packages("knitr")   # For creating a table
#install.packages("kableExtra") # For formatting tables
#install.packages("scales") 
library(scales)
library(readr)
library(dplyr)
library(knitr)
library(kableExtra)

# Load the dataset (update the path if needed)
dataset <- read_csv("~/Downloads/USA_Housing_Dataset.csv")
# View first few rows
head(dataset)
# Define the updated data dictionary with correct types and levels of measurement
data_dictionary <- tibble::tibble(
  Variable = c("Price", "Bedrooms", "Bathrooms", "Sqft Living", "Sqft Lot", 
               "Floors", "Waterfront", "View", "Condition", "Sqft Above", 
               "Sqft Basement", "Yr Built", "Yr Renovated", "Street", 
               "City", "StateZip", "Country", 
               "Median Area Income", "Median Area House Age", 
               "Median Area Number of Rooms", "Median Area Number of Bedrooms", "Area Population"),
  Type = c("Ratio", "Ratio", "Ratio", "Ratio", "Ratio", 
           "Ratio", "Nominal", "Ordinal", "Ordinal", "Ratio", 
           "Ratio", "Interval", "Interval", "Nominal", 
           "Nominal", "Nominal", "Nominal", 
           "Ratio", "Ratio", 
           "Ratio", "Ratio", "Ratio"),
  Description = c("Sale price of the house (in USD).",
                  "Number of bedrooms in the house.",
                  "Number of bathrooms in the house.",
                  "Total living area in square feet.",
                  "Total lot size in square feet.",
                  "Number of floors in the house.",
                  "Indicates if the house is on the waterfront (Yes/No).",
                  "A rating of the house's view quality.",
                  "Condition of the house (1-5 scale, where 5 is the best).",
                  "Square footage of the house above ground.",
                  "Square footage of the basement.",
                  "Year the house was built.",
                  "Year the house was last renovated.",
                  "Street address of the house.",
                  "City where the house is located.",
                  "State and ZIP code of the house.",
                  "Country where the house is located.",
                  "Median income of residents in the area (in USD).",
                  "Median age of houses in the area.",
                  "Median number of rooms in houses in the area.",
                  "Median number of bedrooms in houses in the area.",
                  "Population of the area.")
)
# Print the data dictionary as a formatted table
data_dictionary %>%
  kable("pipe") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
```

## Summary Statistics
Now we can take a further look at the data to gain initial insights and have an overview of the statistics. We can do this by performing a basic Exploratory Data Analysis (EDA). The code below will display the summary statistics from the dataset.

```{r}
# Install required packages (if not already installed)
#install.packages("readr")      
#install.packages("dplyr")      
#install.packages("ggplot2")    
#install.packages("skimr")      
#install.packages("modeest")    
#install.packages("scales")  # For formatting large numbers
#install.packages("knitr")
# Load libraries
library(readr)
library(dplyr)
library(ggplot2)
library(skimr)
library(modeest)
library(scales)  # New package to format numbers
library(knitr)
# Load the dataset (update the path if needed)
dataset <- read_csv("~/Downloads/USA_Housing_Dataset.csv")
# Check structure of dataset
str(dataset)
# Basic summary statistics without scientific notation
summary_stats <- summary(dataset)
# Format numeric values to remove scientific notation
formatted_summary <- as.data.frame(summary_stats) %>% mutate_all(~ format(., big.mark = ",", scientific = FALSE))
# Print formatted summary statistics as a Markdown table
kable(formatted_summary, caption = "Summary Statistics for Dataset", format = "markdown")
# Additional summary statistics using skimr (without scientific notation)
skimmed_data <- skim(dataset)
# Function to remove scientific notation in skimr output
format_skim <- function(x) {
  if (is.numeric(x)) {
    return(format(x, big.mark = ",", scientific = FALSE))
  } else {
    return(x)
  }
}
# Apply formatting
skimmed_data <- skimmed_data %>%
  mutate(across(where(is.numeric), format_skim))
# Print formatted skimmed statistics as a Markdown table
kable(skimmed_data, caption = "Skim Summary Statistics for Dataset", format = "markdown")
# Function to calculate median
get_median <- function(x) {
  median_value <- median(x, na.rm = TRUE)  # Calculate median, ignoring NAs
  return(median_value)
}
# Calculate median for numeric columns
numeric_cols <- dataset %>% select(where(is.numeric))
median_values <- sapply(numeric_cols, get_median)
# Format median values without scientific notation
median_values <- format(median_values, big.mark = ",", scientific = FALSE)
# Print formatted median values as a Markdown table
kable(as.data.frame(median_values), caption = "Median Values for Numeric Columns", format = "markdown")
```


## Missing Values
Next we need to identify any missing or empty values. The code below will allow us to identify the values. 

```{r}
# Check for missing values (NA counts per column)
missing_values <- colSums(is.na(dataset))
# Print missing values summary
print(missing_values)
```
Thankfully this dataset has no missing values in any of the variables as shown above. If there were any missing values or empty values, some strategies that we could do would be to fill in the missing values with the median for that variable and then conduct a sensitivity analysis. 

## Visualizations
From the code below we will be able to see a histogram of the House Prices. 
```{r}
ggplot(dataset, aes(x = `price`)) +
  geom_histogram(bins = 50, fill = "blue", color = "black", alpha = 0.7) +
  scale_x_log10(labels = scales::comma) +  # Log scale with readable numbers
  labs(title = "Distribution of House Prices (Log Scale)", 
       x = "Price (USD, Log Scale)", y = "Count") +
  theme_minimal()
```

As with most datasets we can see that there are a number of outliers. The histogram shows house prices on a log scale, which helps spread out data that is skewed to higher values. Houses with very high prices (luxury homes) appear as bars towards the far-right end. After looking back through the dataset, the houses with extremely high prices are valid data points (very luxury properties) and are not a result from data entry errors.

Next we can look at a bar plot of the number of houses by the amount of the bedrooms they have. 

```{r}
ggplot(dataset, aes(x = as.factor(`bedrooms`))) +
  geom_bar(fill = "purple", alpha = 0.7) +
  labs(title = "Number of Houses by Bedroom Count", x = "Number of Bedrooms", y = "Count") +
  theme_minimal()

```
The results of this bar plot align with the results we saw previously in the histogram. As just from visual inspection we can see that the number of bedrooms a property has will likely directly relate to its price. While there are other factors that play a part in the price of a property (such as location and square footage), it can be concluded that the number of bedrooms will have a significant impact. No outliers can be seen from this graph. 

Finally we can look at a scatter plot for the sale price of the house vs the total area of square foot living space. 

```{r}
ggplot(dataset, aes(x = `sqft_living`, y = `price`)) +
  geom_point(alpha = 0.5, color = "blue") +
  scale_x_continuous(labels = scales::comma) +  # Format x-axis
  scale_y_continuous(labels = scales::comma) +  # Format y-axis
  labs(title = "House Price vs. Living Area", 
       x = "Living Area (sqft)", 
       y = "Price (USD)") +
  theme_minimal()
```
The scatter plot mostly aligns with the trend seen across all graphs that as the number of bedrooms and the total living area increases, so does the houses price. There is two clear outliers that we can see from this graph however. These isolated points far from the cluster of most data indicate potential anomalies. Typically, these high-priced small homes are due to unique factors (e.g., location, luxury features). A NYC penthouse is going to be worth a lot more than a ranch in Jersey, even though it will be significantly smaller. There is no need to  remove these cases as they do not skew statistical models. 



